\documentclass[notes]{subfiles}
\externaldocument{determinants}

\begin{document}

\setcounter{section}{6}
\section{Differential k-forms}
\subsection{Definition of k-forms}

\begin{definition}[Differential $k$-Form]
    $\alpha$ is a \textit{$k$-form} \textit{on} $\real^n$ iff $\alpha$ is a map from every $k$-parallelotope in $\real^n$ to a scalar in $\real$ such that $\alpha$ is
    \begin{enumerate}[label = (\arabic*)]
        \item scaling with respect to the scale of any spanning vector
        \[
            \alpha_p(\ldots, t\vec{v}, \ldots) = t\alpha_p(\ldots, \vec{v}, \ldots)
        \]
        \item additive for each spanning vector
        \[
            \alpha_p(\ldots, \vec{u} + \vec{v}, \ldots) = \alpha_p(\ldots, \vec{u}, \ldots) + \alpha_p(\ldots, \vec{v}, \ldots)
        \]
        \item alternating with respect to swapping any two spanning vectors
        \[
            \alpha_p(\ldots, \vec{u}, \ldots, \vec{v}, \ldots) = -\alpha_p(\ldots, \vec{v}, \ldots, \vec{u}, \ldots)
        \]
        \item $C^1$ smooth with respect to $p$
    \end{enumerate}
\end{definition}

\begin{example}
    Consider the $2$-form $dx \wedge dy$ on $\real^3$ such that
    \[
        (dx \wedge dy)_p(\vec{v}, \vec{w}) =
        \begin{vmatrix}
            a_1 & b_1 \\
            a_2 & b_2
        \end{vmatrix}
    \]
    By the axioms of a determinant, $dx \wedge dy$ (and all other basis exterior product forms) follow axioms 1--3 of a $k$-form. As long as the function in front of the determinant is smooth with respect to $p$ then we get a $k$-form. In this case it is the constant function so this is a $2$-form.

    Also notice that $(dx \wedge dy)_p(\vec{u}, \vec{v})$ will give us the oriented area of the parallelogram spanned by $\vec{u}$ and $\vec{v}$ when projected down to the $xy$ plane.

    Similarly we can define $2$-forms
    \[
        (dx \wedge dz)_p(\vec{v}, \vec{w}) =
        \begin{vmatrix}
            a_1 & b_1 \\
            a_3 & b_3
        \end{vmatrix}
    \]
    and
    \[
        (dy \wedge dz)_p(\vec{v}, \vec{w}) =
        \begin{vmatrix}
            a_2 & b_2 \\
            a_3 & b_3
        \end{vmatrix}
    \]
    which will give us the oriented area of the parallelogram spanned by $\vec{u}$ and $\vec{v}$ when projected down to the $xz$ and $yz$ planes respectively.
\end{example}

\begin{example}
    Let $\vec{F}\colon \real^3 \to \real^3$ be a $C^1$ smooth vector field. We can think of $\vec{F}(p)$ as describing the velocity of a fluid at point $p$.

    Now consider a point $p$ and the parallelogram spanned by $\vec{u}$ and $\vec{v}$ at $p$. We can consider a basis of parallelogram subspace $U$ as $\beta = \{ \vec{u}, \vec{v} \}$. We can now orthonormally extend $\beta$ to a new basis $\beta' = \beta \cup \{ \vec{n} \}$. We can now define the flux through $p$ as
    \[
        (\vec{F}(p)\cdot\vec{n})\det(\vec{u}|_U, \vec{v}|_U)
    \]
    Notice that $\vec{F}(p)\cdot\vec{n}$ is the signed magnitude of $\vec{F}(p)$ that does not lie in $\lspan \beta$ the flux through $p$ will scale the area of the parallelogram formed by $\vec{u}$ and $\vec{v}$ by exactly the signed magnitude of $\vec{F}(p)$ orthogonal to the parallelogram. Therefore the flux is equal to the volume of the parallelopiped spanned by $\vec{u}$, $\vec{v}$, and $\vec{F}(p)$ or
    \[
        \det(v, w, \vec{F}(p))
    \]
    We now associate a flux form to $\vec{F}$ as the $2$-form $\omega$ defined by
    \begin{align*}
        \omega_p(\vec{u}, \vec{v})
        &= \det(\vec{u}, \vec{v}, \vec{F}(p))
        = \begin{vmatrix}
            a_1 & b_1 & F_1(p) \\
            a_2 & b_2 & F_2(p) \\
            a_3 & b_3 & F_3(p)
        \end{vmatrix} \\
        &= F_1(p)\begin{vmatrix}
            a_2 & b_2 \\
            a_3 & b_3
        \end{vmatrix}
        - F_2(p)\begin{vmatrix}
            a_1 & b_1 \\
            a_3 & b_3
        \end{vmatrix}
        + F_3(p)\begin{vmatrix}
            a_1 & b_1 \\
            a_2 & b_2
        \end{vmatrix}
    \end{align*}
    Therefore we can write $\omega$ as
    \[
        \omega = F_1(p)dy\wedge dz - F_2(p)dx\wedge dz + F_3(p)dx \wedge dy
    \]
\end{example}

\subsection{Writing k-forms in coordinates}
\begin{definition}[Multi-Index]
    A \textit{multi-index} of \textit{length} $k$ \textit{for} $n$ is $I = \{i_j\}_{j = 1}^k$ such that for each $i_j \in \mathbb{Z}$ where $1 \leq i_j \leq n$.
\end{definition}
This gives us a way to properly choose a set of indices for a problem. Note that the ``set" we work with here is not a set in the formal definition of the term. Specifically, this set is prescribed a specific order (i.e $\{ 1, 2 \} \neq \{ 2, 1 \}$), and elements do not need to be unique (i.e $\{ 1, 1 \} \neq \{ 1 \}$).

\begin{example}
    If we have a multi-index $I = \{1, 5, 2\}$ then $\bigwedge_{i \in I} dx_i = dx_1 \wedge dx_5 \wedge dx_2$
\end{example}

\begin{definition}[$k$-Form for a Multi-Index] \label{multi_index_k_form}
    If $I$ is a multi-index of length $k$ for $n$, then $dx_I = \bigwedge_{i \in I} dx_i$ is the \textit{multi-indexed $k$-form} on $\real^n$ \textit{for} $I$ defined by
    \[
        (dx_I)_p(A)
        = \det(A_{i, j})_{i \in I, j = 1}^{\emptyset, k}
    \]
    By the properties of the determinant and being constant with respect to $p$, it is sensible to call these $k$-forms.
\end{definition}

We can view \cref{multi_index_k_form} as taking $k$ vectors and projecting them down to a subspace and then computing the volume of these projected vectors.

Notice that if there are any repeated indices in $I$ then $dx_I = 0$ by the alternating property. Also if $J$ is a multi-index obtained by swapping two indices from $I$ then $dx_I = -dx_J$ by the alternating property.

\begin{example}
    Let $\alpha$ be a $k$-form on $\real^n$ defined by
    \[
        \alpha = \sum_{i = 1}^m f_i(p) dx_{I_i}
    \]
    for multi-indices $[I_i]_{i = 1}^m$ each of length $k$ and $C^1$ smooth functions $[f_i\colon \real^n \to \real]_{i = 1}^m$. We inherit axioms 1--3 from $dx_{I_i}$ and we are smooth with respect to $p$ so this is a $k$-form.
\end{example}

Also notice that we can always rewrite a multi-index $I$ to be in increasing order of indices as $J$ which gives us $dx_J = \pm dx_I$.

\begin{definition}[Increasing Multi-Index]
    A multi-index $I = \{ i_j \}_{j = 1}^k$ is \textit{increasing} iff $\bigless_{j = 1}^{k} i_j$.
\end{definition}

\begin{example}
    $\{ 2, 4, 8 \}$ is increasing but $\{ 2, 1, 3 \}$ and $\{ 2, 2, 2 \}$ are not.
\end{example}

\begin{lemma}
    There are $\binom{n}{k}$ increasing multi-indices of length $k$ for $n$.
\end{lemma}
% I am not proving this

\begin{example}
    Consider multi-indices of length $2$ for $4$. Then all of the increasing multi-indices are $(1, 2)$, $(1, 3)$, $(1, 4)$, $(2, 3)$, $(2, 4)$, $(3, 4)$ which totals to $6 = \binom{4}{2}$.
\end{example}

\begin{lemma} \label{increasing_characteristic_lemma}
    If $I$ and $J$ are increasing multi-indices of length $k$ for $n$ such that $\elem I = \elem J$ then $I = J$.
\end{lemma}

\begin{theorem} \label{nonzero_thm}
    If $I = \{i_p\}_{p = 1}^k$ and $J = \{j_q\}_{q = 1}^k$ are increasing multi-indices for $n$, then
    \[
        (dx_I)_p(E_{., j})_{j \in J} = \begin{cases}
            1 & I = J \\
            0 & I \neq J
        \end{cases}
    \]
    where $E$ is the identity matrix for $\real^n$.
\end{theorem}
\begin{proof}
    First, consider the case where $I = J$. We want to show that we end up with the identity matrix $E'$ of $\real^k$. Therefore
    \begin{align*}
        (dx_I)_p(E_{., j})_{j \in J}
        &= (dx_I)_p(E_{., j})_{j \in I}
        = \det(E_{i, j})_{i \in I, j \in I}
        = \det(E_{i_s, i_t})_{s = 1, t = 1}^{k, k} \\
        &= \det\left(\begin{cases}
            1 & i_s = i_t \\
            0 & .
        \end{cases}\right)_{s = 1, t = 1}^{k, k}
    \end{align*}
    Notice that if $s, t$ existed such that $i_s = i_t$ and $s \neq t$, then $I$ would not have distinct indices so $I$ would not be increasing. Therefore $i_s = i_t$ implies $s = t$ which means
    \begin{align*}
        (dx_I)_p(E_{., j})_{j \in J}
        &= \det\left(\begin{cases}
            1 & s = t \\
            0 & .
        \end{cases}\right)_{s = 1, t = 1}^{k, k}
    \end{align*}
    Notice that \[
        \left(\begin{cases}
            1 & s = t \\
            0 & .
        \end{cases}\right)_{s = 1, t = 1}^{k, k}
    \]
    is our desired identity matrix $E'$ of $\real^k$ so
    \begin{align*}
        (dx_I)_p(E_{., j})_{j \in J}
        &= \det(E')
        = 1
    \end{align*}
    Now consider the case where $I \neq J$. We want to show that at least one column vector ends up as zero. Therefore
    \begin{align*}
        (dx_I)_p(E_{., j})_{j \in J}
        &= \det(E_{i, j})_{i \in I, j \in J}
        = \det(E_{i_s, j_t})_{s = 1, t = 1}^{k, k}
    \end{align*}
    Notice that by \cref{increasing_characteristic_lemma} there must exist some $t'$ such that $j_{t'} \notin I$, so
    \begin{align*}
        (dx_I)_p(E_{., j})_{j \in J}
        = \det(\ldots, (E_{i_s, j_{t'}})_{s = 1}^k, \ldots)
    \end{align*}
    We now want to show that the $(t')$-th column vector is zero. Consider that if there existed $s$ such that $i_s = j_{t'}$ then that would mean $j_{t'} \in I$ but that is a contradiction. Therefore $i_s \neq j_{t'}$ for $s = 1$ to $k$ so $E_{i_s, j_{t'}} = 0$. Therefore we get
    \begin{align*}
        (dx_I)_p(E_{., j})_{j \in J}
        &= \det(\ldots, 0, \ldots)
        = 0
    \end{align*}
\end{proof}

\begin{lemma}
    If $\{I_i\}_{i = 1}^m$ is the ordered set of all increasing multi-indices of length $k$ for $n$, then $\{dx_{I_i}\}_{i = 1}^m$ is linearly independent at every point.
\end{lemma}
\begin{proof}
    We want to use \cref{nonzero_thm} to cancel out the right terms and leave us with just the coefficients.

    Then for any $p$, consider constants $[a_i]_{i = 1}^m$ such that
    \[
        \sum_{i = 1}^m a_i (dx_{I_i})_p = 0
    \]
    then that means
    \[
        \left(\sum_{i = 1}^m a_i dx_{I_i}\right)_p(A) = 0
    \]
    Now consider that for $j = 1$ to $m$ that
    \begin{align*}
        0
        &= \left(\sum_{i = 1}^m a_i dx_{I_i}\right)_p(E_{\cdot, p})_{p \in I_j} = \sum_{i = 1}^m a_i(dx_{I_i})_p(E_{\cdot, p})_{p \in I_j}
        = a_j
    \end{align*}
    Therefore $a_j = 0$ so $\{dx_{I_i}\}_{i = 1}^m$ is linearly independent.
\end{proof}

\begin{theorem}
    If $\{I_i\}_{i = 1}^m$ is the ordered set of all increasing multi-indices of length $k$ for $n$, then $\{dx_{I_i}\}_{i = 1}^m$ generates all $k$-forms on $\real^n$ at every point.
\end{theorem}
% \begin{proof}
%     We want to fix the values of our coefficients at multi-indexed identity matrices.

%     Then for any $k$-form $\omega$ at any point $p$, consider constants $[a_i]_{i = 1}^m$ such that
%     \[
%         a_i = \omega_p(E_{., j})_{j \in I_i}
%     \]
%     where $E$ is the identity matrix of $\real^n$. Now consider
%     \begin{align*}
%         \sum_{i = 1}^m a_i (dx_{I_i})_p
%     \end{align*}
% \end{proof}

Therefore we have shown that $\{dx_{I_i}\}_{i = 1}^m$ is a basis for $k$-forms on $\real^n$ at every point.

\end{document}